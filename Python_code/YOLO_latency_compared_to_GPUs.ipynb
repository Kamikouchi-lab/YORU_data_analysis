{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f410aef-9496-4a5a-b7c6-804ee5ef8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from natsort import natsorted\n",
    "from itertools import chain\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import brunnermunzel\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feea6c5c-8035-47dd-ad87-23342e00845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check directory\n",
    "current_dir = \"..\"\n",
    "data_dir = \"../raw_csv\"\n",
    "result_dir = \"../reshape_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8891f6-7f00-4f96-8541-c19eec238afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv function\n",
    "def fast_concat(dfs):\n",
    "    def fast_flatten(input_list):\n",
    "        return list(chain.from_iterable(input_list))\n",
    "\n",
    "    col_names = dfs[0].columns\n",
    "    df_dict = dict.fromkeys(col_names, [])\n",
    "    for col in col_names:\n",
    "        extracted = (d[col] for d in dfs)\n",
    "        df_dict[col] = fast_flatten(extracted)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(df_dict)[col_names]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc84766-e3ad-466a-a288-a880213f8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums setting\n",
    "# colums_name = [\"frame\", \"time\", \"GPU\", \"size\", \"model\"]\n",
    "colums_name = [\"frame\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9db1d6-66e1-4b0f-bd44-b0f8b38782a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = glob.glob(data_dir + \"/*.csv\")\n",
    "df = pd.DataFrame()\n",
    "dfs = []\n",
    "list_file = []\n",
    "gpulist = []\n",
    "sizelist = [\"640\", \"1280\"]\n",
    "# modellist = [\"yolov5l\", \"yolov5m\", \"yolov5x\", \"yolov5s\", \"yolov5n\" ]\n",
    "modellist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4da85a-5a61-4777-8ef6-aa9c7a972a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013298988342285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b876bf4e09694fc094c68eb5ccca33d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     list_file \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(csv)]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     print(fname)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     # draw histgram\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     fig, ax = plt.subplots(1,1,dpi = 300)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     del dfss\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#     plt.close(fig)  # この行でプロットに関連するメモリを解放します\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfast_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m csv_save_path \u001b[38;5;241m=\u001b[39m result_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/results_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(csv_save_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mfast_concat\u001b[0;34m(dfs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfast_flatten\u001b[39m(input_list):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(input_list))\n\u001b[0;32m----> 6\u001b[0m col_names \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      7\u001b[0m df_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(col_names, [])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m col_names:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(csvs):\n",
    "    # passing 1 rows\n",
    "    dfss = pd.read_csv(csv, header=None, skiprows=1, names = colums_name)\n",
    "    dfss = dfss.iloc[:50000]\n",
    "    \n",
    "    # extract info from file name\n",
    "    fname = os.path.basename(csv)\n",
    "    parts = fname.split('_')\n",
    "    dfss[\"size\"] = parts[0]\n",
    "    dfss[\"model\"] = parts[1]\n",
    "    dfss[\"GPU\"] = parts[3]\n",
    "    gpulist.append(str(parts[3]))\n",
    "    modellist.append(str(parts[1]))\n",
    "#     print(str(parts[3]))\n",
    "    dfs += [dfss]\n",
    "    list_file += [os.path.basename(csv)]\n",
    "    \n",
    "#     print(fname)\n",
    "#     # draw histgram\n",
    "#     fig, ax = plt.subplots(1,1,dpi = 300)\n",
    "#     ax = sns.histplot(\n",
    "#       data = dfss,\n",
    "#       x = \"time\",\n",
    "#       color=\"b\",\n",
    "#       alpha = 0.3\n",
    "#     )\n",
    "#     ax.set_xlabel(\"Time (s)\")\n",
    "#     # ax.set_ylabel(\"count\")\n",
    "#     ax.set_title(fname)\n",
    "    \n",
    "#     save_path = result_dir + \"/\" + fname + \"_histgram.png\"\n",
    "#     figure = fig.get_figure()\n",
    "#     figure.savefig(save_path, format=\"png\", dpi=300)\n",
    "#     print(fname, gpulist)\n",
    "    \n",
    "#     # 不要な変数を削除してメモリを解放\n",
    "#     del dfss\n",
    "#     plt.close(fig)  # この行でプロットに関連するメモリを解放します\n",
    "    \n",
    "    \n",
    "df = fast_concat(dfs)\n",
    "csv_save_path = result_dir + \"/results_data.csv\"\n",
    "df.to_csv(csv_save_path, index=False)\n",
    "\n",
    "df_4080 = df[df[\"GPU\"] == \"NVIDIA GeForce RTX 4080\"]\n",
    "# print(df[\"model\"])\n",
    "print(df_4080)\n",
    "csv_4080_save_path = result_dir + \"/results_data_rtx4080.csv\"\n",
    "df_4080.to_csv(csv_4080_save_path, index=False)\n",
    "\n",
    "gpulist = list(set(gpulist))\n",
    "modellist = list(set(modellist))\n",
    "print(gpulist)\n",
    "\n",
    "\n",
    "d = \"\\n\".join(list_file)\n",
    "info_path = result_dir + \"/info.txt\"\n",
    "with open(info_path, 'w') as f:\n",
    "    f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b83fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical analysis\n",
    "statistical_df = pd.DataFrame()\n",
    "for gpu in tqdm(gpulist):\n",
    "    f_df = df[df[\"GPU\"] == gpu]\n",
    "    for size in sizelist:\n",
    "        fi_df = f_df[f_df[\"size\"] == size]\n",
    "        for model in modellist:\n",
    "            filtered_df = fi_df[fi_df[\"model\"] == model]\n",
    "            df_stats = filtered_df.describe()\n",
    "            print(df_stats)\n",
    "            selected_stats = df_stats[['time']].transpose()\n",
    "            selected_stats[\"GPU\"] = gpu\n",
    "            selected_stats[\"size\"] = size\n",
    "            selected_stats[\"model\"] = model\n",
    "            statistical_df = pd.concat([statistical_df, selected_stats], axis=0)\n",
    "#             print(selected_stats)\n",
    "#             print(df_stats)\n",
    "            \n",
    "\n",
    "statistical_df = statistical_df.reset_index(drop=True)\n",
    "stats_save_path = result_dir + \"/statistical_results.csv\"\n",
    "statistical_df.to_csv(stats_save_path, index=False)\n",
    "print(statistical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd37be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical analysis reshape\n",
    "result_df = pd.DataFrame()\n",
    "count = 0\n",
    "# res_df = pd.DataFrame()\n",
    "for gpu_s in tqdm(gpulist):\n",
    "    s_f_df = statistical_df[statistical_df[\"GPU\"] == gpu_s]\n",
    "    for size_s in sizelist:\n",
    "        res_df = pd.DataFrame()\n",
    "        s_fi_df = s_f_df[s_f_df[\"size\"] == size_s]\n",
    "        data = {\n",
    "            'GPU': gpu_s,\n",
    "            'size': size_s\n",
    "                }\n",
    "#         res_df[\"size\"] = size_s\n",
    "#         res_df[\"GPU\"] = gpu_s\n",
    "        res_df = pd.DataFrame(data, index=[0])\n",
    "#         print(res_df)\n",
    "        for model in modellist:\n",
    "            s_filtered_df = s_fi_df[s_fi_df[\"model\"] == model].reset_index(drop=True)\n",
    "#             print(s_filtered_df)\n",
    "            mean = s_filtered_df.loc[0, 'mean']\n",
    "            mean = mean*1000\n",
    "            mean = round(mean, 1)\n",
    "            if model == \"yolov5s\":\n",
    "                mean_n = mean\n",
    "            std = s_filtered_df.loc[0, 'std']\n",
    "            std = std*1000\n",
    "            std = round(std, 1)\n",
    "            value = str(mean) + \"±\" + str(std)\n",
    "#             sort = mean\n",
    "#             print(value)\n",
    "            res_df[model] = str(value)\n",
    "        res_df[\"sort\"] = mean_n\n",
    "        res_df[\"sort_no\"] = count\n",
    "#         print(res_df)\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        result_df = pd.concat([result_df, res_df], axis=0)\n",
    "        \n",
    "# sort\n",
    "sorted_df = result_df[result_df[\"size\"] == \"640\"].sort_values(by='sort')\n",
    "# print(sorted_df)\n",
    "\n",
    "# sort list\n",
    "new_list = []\n",
    "sort_list = sorted_df[\"sort_no\"].tolist()\n",
    "# print(sort_list)\n",
    "for num in sort_list:\n",
    "    new_list.append(num)\n",
    "    new_list.append(num + 1)\n",
    "result_df = result_df.set_index(\"sort_no\").reindex(new_list).reset_index()\n",
    "\n",
    "name_list = [\"GPU\", \"size\", \"yolov5n\", \"yolov5s\", \"yolov5m\", \"yolov5l\", \"yolov5x\"]\n",
    "\n",
    "\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "result_df = result_df.drop(columns=[\"sort_no\"])\n",
    "result_df = result_df.drop(columns=[\"sort\"])\n",
    "\n",
    "result_df = result_df.reindex(columns=name_list)\n",
    "stats_reshape_save_path = result_dir + \"/statistical_reshape_results.csv\"\n",
    "result_df.to_csv(stats_reshape_save_path, index=False)\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
